\chapter{Introduction}
\label{introduction}

Nowadays, the Internet and software systems are being used even in an old-fashioned area like communication via push-to-talk devices. Even though it was not so long ago that this was only done over analog networks. Today, the traditional use case can be complemented by software that detects poor analogue network coverage and eventually switches to a digital connection if necessary. 

The Motorola SmartConnect \cite{apxnextfactsheet} system was developed for this purpose. 
Since this software system serves people in critical professional positions such as police officers or firefighters, it is crucial that the SmartConnect infrastructure is as robust as possible.

In order to improve the robustness of the system, we are trying to propose a solution that is able to speed up and automate the process of handling a fault.

When something goes wrong, the first step is to identify that a problem has occurred. 
Then it is desired to be able to answer when and where the problem occurred so that one can respond to it.

In order to monitor the state of a software system and troubleshoot issues, it is a good practice for developers to implement logging.
Motorola SmartConnect is a complex system that consists of many different services. It produces dozens of gigabytes of log data per day in logs that are increasingly difficult to evaluate manually \cite{anomalydetectiondistributedsystems}.

Not only is it far too much information in terms of size, the logs from different parts of the software can be located at different places and it is unrealistic to expect one person to uncover the internal relationships between different services that lead to errors.

It is also not tangible to use human workers to observe the live logs of the system. Furthermore, it would be desirable to anticipate potential faults and raise alarms while they have not yet done any damage. 
But in reality, we usually don't know about a problem until something crashes, despite red flags might have been raised earlier, when the system started behaving in a non-standard way. 
In that gap, between the moment when the software appears to be in a state that is not stable and leads to an error and the actual error, can be a space for intervention that can get the program back on the right track.

The goal of our thesis is to address all of these problems. 
In our research, we will investigate whether anomaly detection techniques can be used to develop a reliable solution that makes the error recovery process less dependent on human intervention \cite{logCluster2016} \cite{pca1997} \cite{lou2010} \cite{liu2012isolation}.
The solution should help the developers of Motorola SmartConnect, the customer support team and finally the end users who would have a better tool for their critical communication.

Looking at the logs generated by the telecommunication system as time series data should allow us to experiment with machine learning techniques \cite{wang2017timeseriesanomaly}. These techniques should allow us to explore scenarios that lead to faulty runs of the system.

After proving that it is indeed possible to observe anomalies in such data, we want to propose an automated tool capable of performing this cumbersome work autonomously, monitoring the Motorola SmartConnect software system and raising an alarm when a critical finding is present.

The output of our tool would initially serve as a fairly specific piece of information that a responsible person can use and proceed with solving the reported problem with significantly narrowed scope of the issue and further investigate for the alleged problem.

In this thesis, we attempt to define the steps necessary to achieve such a solution. We also show which possible strategies and tools can be used in each of the steps, reason and justify which possibilities are the optimal ones for our use case.


\section {Research Questions}

% Main Objective
In this work, we will investigate anomalies in Motorola SmartConnect logs and apply machine learning based anomaly detection techniques to the dataset.

First, we conducted a systematic literature review on research work that has been done so far in the field of anomaly detection on log data. There has been a good amount of work done before, so we can evaluate which methods have been used on problems similar to ours and what their advantages and disadvantages are. Based on this, we select some approaches that seem to be well suited, and we argue why it is useful to apply them to our data.

% Then the method of anomaly detection itself.
Since the main goal of our thesis is to apply anomaly detection methods to a real-world dataset, it may be noisy, which is often the case for large system logs that were not intended as input to machine learning-based anomaly detection in the first place. 
We also need to find out if the logs are generated in a way that is suitable and sufficient for anomaly detection. Thus, our first research question is:\\

\textbf{RQ1}: \textit{\RQFirst}\\
    
The first research question lies at the heart of our research. To find an answer, we will develop and follow a methodology to study log-based anomaly detection in SmartConnect data. We consider the first question answered if we can find a means to group logs based on their underlying events. Once identified, the anomalous or non-anomalous class of these groups or clusters should be distinguishable. This could be done both by exploring the dataset and by conducting experiments.

Since the challenging part of the experiments is to design an appropriate embedding of logs after extracting log templates, our second research question is:\\ 


\textbf{RQ2}: \textit{\RQSecond}\\

If this is the case and we are able to detect the outliers in plots based on our embedding, it should be possible to find an algorithm that can do this task automatically. Since we have large datasets available, we plan to use machine learning algorithms, which in theory should be more scalable and flexible for this kind of problems in large software systems.
Therefore, we are looking for an answer to this question:\\


\textbf{RQ3}: \textit{\RQThird}\\
    
Assuming we find some algorithms that meet our expectations and are well suited for this use case, we will proceed with the selected ones and perform a series of experiments.
We will evaluate them and justify the results. In the case of poor results, we will elaborate on what could be improved in the machine learning approaches or what would be a better logging strategy that would give us better results.
So the final question to be addressed in the thesis is:\\

\textbf{RQ4} \textit{\RQFourth}\\ 
    
%To validate the results and evaluate the machine learning techniques used, we created a manually labeled dataset.


\section{Related Work}
Log-based anomaly detection has been widely studied. Anomaly detection research usually follows similar steps. First, a log parser is used to extract log templates from unstructured log data. Then, logs are transformed into a numerical feature vector using the log templates. Last, anomaly detection techniques are applied.
Different approaches to each of these steps have been presented in previous work on this topic. 

Xu et al. \cite{xu2009} was one of the first to use Principal Component Analysis (PCA) to detect anomalies in log data. They generated event templates based on the source code and used the event count matrix as input to PCA. To form an input, Xu uses the concept of windowing by session, where all logs with the same session ID are grouped together. The event count matrix is constructed such that each vector in a row represents events in a session ID and each column vector is an event type. The dataset used for their experiments was collected from Hadoop Distributed File System (HDFS).
A similar approach was used by He \cite{he2016}, which also used an event count matrix. To extract features, they group log data into three groups: fixed windows, sliding windows, and session windows. 

Invariant Mining (IM) method was developed by Lou et al. \cite{lou2010}, also using the log event count matrix as input. IM mines the invariants between log events from the event count vectors. Event count vectors that do not satisfy the determined invariants are considered as anomalies. 

Since Deep Learning performs better than traditional machine learning as the amount of data increases \cite{Sydney2019DeepLF}, neural networks have recently been applied to the problem of anomaly detection in system logs. 

Du et al. \cite{deeplog2017} used a Deep Neural Network (DNN) model consisting of Long Short-Term Memory (LSTM) units to model logs as a natural language sequence. The model is trained with non-anomalous log data. In this way, the LSTM can automatically learn the normal behaviour, forecast the next event type, and identify anomalies when it differs from the actual event type. Similarly, Zhang et al. \cite{zhang2016} and DeepLog \cite{deeplog2017} also use an LSTM deep learning approach. The former borrows an idea from Term Frequency-Inverse Document Frequency (TF-IDF) by considering all logs in each time window as one document and using TF-IDF weight as a feature representation. The latter work differs from other DNN approaches in that it preserves the timestamp when encoding the log message and performs anomaly detection for each log entry rather than for each session.

\section{Outline}
In Chapter~\ref{smart-connect}, we introduce the domain of our problem by describing the SmartConnect product from Motorola Solution, whose log data is examined in the thesis. We also introduce the reader to the software architecture of SmartConnect. 

In the following chapter, Chapter~\ref{chapter:literatureReview}, we review related work done by researchers before us. Methods relevant to our work and used in our approach are analyzed in detail.

Methodology ( Chapter \ref{methodology}), explains exactly how we proceeded with our solution. It starts with a simple example that provides the motivation for an anomaly detection tool in SmartConnect. We then outline the exact steps we took and describe them comprehensively. More specifically, it consists of data collection, log parsing, feature engineering, anomaly detection, and finally mapping predictions back to log entries.

Later in Chapter~\ref{chapter:dataset} we describe the data we work with in our research. From the test dataset to the data used for validation. Some concrete examples of anomalies that occur in the system and can be recorded by logs are presented.

Chapter~\ref{chapter:experiments} is devoted to experiments. It discusses in detail what we can learn from datasets by examining the data using data exploration techniques.
It provides a strong intuition for what we expect to learn when we apply machine learning before we actually do it. 
The metrics we use for evaluation are explained along with working out the setup for the experiments.

Chapter~\ref{results} presents the results we obtained by applying four different machine learning techniques to our anomaly detection problem. We explain why the different machine learning methods give slightly more or less accurate results on our datasets.

Finally, in Chapter~\ref{conclusion}, we reflect on our research and suggest new questions that arise from our work that we think may be worth investigating further in the future.